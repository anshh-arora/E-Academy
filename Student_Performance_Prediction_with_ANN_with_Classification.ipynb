{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppajewski/ANN-Students-Performance-Prediction/blob/master/Student_Performance_Prediction_with_ANN_with_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tk1OyXXDtbUe"
      },
      "source": [
        "In this notebook we are going to train ANN model to predict students grades. Description of the data may be found at:\n",
        "https://archive.ics.uci.edu/ml/datasets/student+performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MxkJoQBkUIHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MXUkhkMfU4wq"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('student-mat.csv', sep=';')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SPZcpOhsknui"
      },
      "source": [
        "Let's say that we want to predict the grade that student gets. We divide points into 5 categories:\n",
        "\n",
        "Grade | Points needed for the grade \n",
        "------ | -------\n",
        "0 | $0 \\leq x < 4$\n",
        "1 | $4 \\leq x < 8$\n",
        "2 | $8 \\leq x < 12$\n",
        "3 | $12 \\leq x < 16$\n",
        "4 | $16 \\leq x $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tLHI2x-qisvq"
      },
      "outputs": [],
      "source": [
        "for i in range(y.shape[0]):\n",
        "  if y[i] < 4:\n",
        "    y[i] = 0\n",
        "  if 4 <= y[i] < 8:\n",
        "    y[i] = 1\n",
        "  if 8 <= y[i] < 12:\n",
        "    y[i] = 2\n",
        "  if 12 <= y[i] <= 16:\n",
        "    y[i] = 3\n",
        "  if 16 <= y[i]:\n",
        "    y[i] = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2nq1QT6Zvtlg"
      },
      "source": [
        "Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "colab_type": "code",
        "id": "025PYyktvwqu",
        "outputId": "ae2ab8ca-2b7a-49a9-c80a-c67439e69974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "school        0\n",
            "sex           0\n",
            "age           0\n",
            "address       0\n",
            "famsize       0\n",
            "Pstatus       0\n",
            "Medu          0\n",
            "Fedu          0\n",
            "Mjob          0\n",
            "Fjob          0\n",
            "reason        0\n",
            "guardian      0\n",
            "traveltime    0\n",
            "studytime     0\n",
            "failures      0\n",
            "schoolsup     0\n",
            "famsup        0\n",
            "paid          0\n",
            "activities    0\n",
            "nursery       0\n",
            "higher        0\n",
            "internet      0\n",
            "romantic      0\n",
            "famrel        0\n",
            "freetime      0\n",
            "goout         0\n",
            "Dalc          0\n",
            "Walc          0\n",
            "health        0\n",
            "absences      0\n",
            "G1            0\n",
            "G2            0\n",
            "G3            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(dataset.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oec06e3awinu"
      },
      "source": [
        "No values missing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the binaray categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PxVKWXxLbczC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "r = [0, 1, 3, 4, 5]\n",
        "le = LabelEncoder()\n",
        "for i in r:  \n",
        "  X[:, i] = le.fit_transform(X[:, i]) \n",
        "for i in range(15, 23, 1):\n",
        "  X[:, i] = le.fit_transform(X[:, i]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KniypijWRiq-"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the text columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AMXC8-KMVirw"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [8, 9, 10, 11])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z-TDt0Y_XEfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ViCrE00rV8Sk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3dtrScHxXQox"
      },
      "outputs": [],
      "source": [
        "ann = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IR0qAKJdQyKn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\arora\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\regularization\\dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dropout\n",
        "ann.add(tf.keras.layers.Dense(units=40, activation='relu'))\n",
        "ann.add(Dropout(0.2, input_shape=(40,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JneR0u0sYRTd"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
        "ann.add(Dropout(0.2, input_shape=(100,)))\n",
        "ann.add(tf.keras.layers.Dense(units=60, activation='relu'))\n",
        "ann.add(Dropout(0.2, input_shape=(60,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cn3x41RBYfvY"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fcfY7fl6z_4g"
      },
      "source": [
        "Number of units in the output layer corresponds to number of categories to be predicted - here we have grades from 0 to 4 so we need 5 units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fG3RrwDXZEaS"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ip9MP-lZ0pqB"
      },
      "source": [
        "For binary outcome we must use 'binary_crossentropy' for the loss function. \\\n",
        "For non-binary outcome we use 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VoeK3Xzv2AHS"
      },
      "source": [
        "Batch learning is alwys more efficent - it takes batches of predictions and compares them to batches of results rather than comparing one by one. 32 is recomended, default value (we can fine-tune it to the problem as well). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "nHZ-LKv_ZRb3",
        "outputId": "88efaa54-62c5-4931-f39b-026e30b63efe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1e1ac189bb0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 2000,verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "colab_type": "code",
        "id": "ci6K_r6LaF6P",
        "outputId": "74689904-0224-4a61-8428-d0953f3c4342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "[[[68  8]\n",
            "  [ 0  3]]\n",
            "\n",
            " [[70  2]\n",
            "  [ 5  2]]\n",
            "\n",
            " [[39  2]\n",
            "  [ 9 29]]\n",
            "\n",
            " [[45  3]\n",
            "  [ 5 26]]\n",
            "\n",
            " [[75  4]\n",
            "  [ 0  0]]]\n",
            "Accuracy score: 75.9493670886076%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "cm = multilabel_confusion_matrix(y_pred, y_test)\n",
        "print(cm)\n",
        "print(f\"Accuracy score: {accuracy_score(y_test, y_pred)*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.05169965,  0.5942192 ,  0.00747026,  0.27865202, -0.10819261],\n",
              "       [ 0.04216736,  0.45824339,  0.86807028,  0.08590825, -0.06359042]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regr.predict(X_test[:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.5181777190999677"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regr.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Student Performance Prediction with ANN with Classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
